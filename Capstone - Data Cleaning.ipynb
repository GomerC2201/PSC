{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "700fa7be",
   "metadata": {},
   "source": [
    "# US Public School Characteristics - 2020 - 21"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31528c31",
   "metadata": {},
   "source": [
    "#### Project Description\n",
    "\n",
    "Starting off, and before I even found the datasets this analysis covers, I wanted to find a way to look at average teacher salary in the US and what factors affect salary the most for public school teachers across the country. While my analysis didn't end up covering that aspect as much as I originally intended, it did offer some surprising insights in regard to the vast differences students and teachers face when it comes to public schools in different locales, states, and regions in the US.\n",
    "\n",
    "#### Insights\n",
    "\n",
    "Overall, this notebook covers my process of working with the Public School Characteristics 2020-2021 dataset, and the massaging it took to get to the dataset I ended up analyzing. The finished article focuses primarily on school locations, student and teacher populations, student demographics, income-to-poverty ratio, and school locale.\n",
    "\n",
    "In the end, this part of the project was most useful as an exercise in recording cleaning steps and process. As this was done individually, there are some ease-of-use features with excel that make filtering on multiple criteria a bit easier and faster than using Python, especially when investigating prior to cleaning. However, I included examples of how the process would be done using Python here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb432c7c",
   "metadata": {},
   "source": [
    "# Data Cleaning \n",
    "Getting familiar with Public School Characteristics\n",
    "\n",
    "To start, I imported the [Public School Characteristics csv file](https://data-nces.opendata.arcgis.com/datasets/nces::public-school-characteristics-current-1/explore?location=40.939600%2C-109.200589%2C8.89![image.png](attachment:image.png) in order to get an idea of what information was useful and could be removed. Fortunately, when I downloaded the dataset from the NCES database, there was a thorough summary of the data and descriptions for each of the columns. So while I needed to rename quite a few of the columns for ease of use, it was easy to verify what I was working with."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29f0e3c5",
   "metadata": {},
   "source": [
    "# Overview of steps\n",
    "Overall, these are the steps that I went through to reach the finished dataset I worked with doing this project. \n",
    "\n",
    "1) Removed unused columns -> These are listed in the pertinent cell below, however there ended up being quite a few columns I did not use. In this workbook, I have removed the same columns as in my original work, however, some of the columns I thought I would need just didn't fit the finished project (such as Title I and Charter/Magnet School classification).\n",
    "\n",
    "2) Renamed LSTATE -> STATE\n",
    "\n",
    "3) Updated TOTAL column -> removed G13 and Adult Education schools, retotaled TOTAL column from PK - G12 columns for consistency.\n",
    "\n",
    "4) Renamed and Rounded FTE -> Total_Teachers_Rounded\n",
    "    4a) For mostly aesthetic reasons, I rounded the FTE column. This was brought on by two main factors, one being that I ended up needing to recalculate S:T Ratio for some schools/states due to odd values (-2, -1, 0, etc), and the other being that it made some of my visualizations easier to present without decimals for the number of teachers.\n",
    "    \n",
    "5) Renamed STUTERATIO -> Student_Teacher_Ratio and recalculated S:T Ratio for schools that were obviously wrong. For the sake of this project, I changed values based on reported Student and FTE numbers. In cases where that was not possible, I replaced blanks or incorrect values with the state reported S:T Ratio for the type of school I was dealing with. This happened on only a handful of records, so overall I don't think it made much difference and they probably could have been removed outright.\n",
    "\n",
    "6) Renamed SY_STATUS_TEXT -> School_Status\n",
    "    6a) Removed all schools that were not listed as \"Currently Operational\" or \"Newly Opened\" due to low impact on the dataset and general irrelevance to my topic. While I think there is value in looking at the closed schools or schools that are planning to reopen, I felt these were outside my scope and due to their low numbers (<1000), not worth keeping.\n",
    "\n",
    "Finally, I also ended up making alternative tables and doing some additional calculations for percentage breakdowns for Demographics, IPR, Locales, and Teacher Salary. However, I think all of these things can be done in Tableau or simply as part of making plots, and I did not include them here. In the end, none of these calculations affected the dataset and did not result in any changes to the overall number of records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b75da7c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import pandas and load the dataset\n",
    "import pandas as pd\n",
    "\n",
    "# Load CSV file\n",
    "df = pd.read_csv(\"/Users/camerongomez/Desktop/Python Cleaning/Schools_Data_2021_2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e58a09e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column names:\n",
      "['OBJECTID', 'X', 'Y', 'NCESSCH', 'SURVYEAR', 'STABR', 'LEAID', 'ST_LEAID', 'LEA_NAME', 'SCH_NAME', 'LSTREET1', 'LCITY', 'LSTATE', 'LZIP', 'PHONE', 'GSLO', 'GSHI', 'VIRTUAL', 'TOTFRL', 'FRELCH', 'REDLCH', 'PK', 'KG', 'G01', 'G02', 'G03', 'G04', 'G05', 'G06', 'G07', 'G08', 'G09', 'G10', 'G11', 'G12', 'G13', 'TOTAL', 'MEMBER', 'AM', 'HI', 'BL', 'WH', 'HP', 'TR', 'FTE', 'LATCOD', 'LONCOD', 'ULOCALE', 'NMCNTY', 'STUTERATIO', 'TITLEI', 'STITLEI', 'AMALM', 'AMALF', 'ASALM', 'ASALF', 'HIALM', 'HIALF', 'BLALM', 'BLALF', 'WHALM', 'WHALF', 'HPALM', 'HPALF', 'TRALM', 'TRALF', 'TOTMENROL', 'TOTFENROL', 'STATUS', 'UG', 'AE', 'SCHOOL_TYPE_TEXT', 'SY_STATUS_TEXT', 'SCHOOL_LEVEL', 'AS', 'CHARTER_TEXT', 'MAGNET_TEXT']\n",
      "Number of columns: 77\n",
      "Number of rows: 99742\n"
     ]
    }
   ],
   "source": [
    "# Print summary information - Get a feel for the data\n",
    "print(\"Column names:\")\n",
    "print(list(df.columns))\n",
    "\n",
    "print(\"Number of columns:\", len(df.columns))\n",
    "print(\"Number of rows:\", len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4189560a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data types:\n",
      "OBJECTID            int64\n",
      "X                 float64\n",
      "Y                 float64\n",
      "NCESSCH           float64\n",
      "SURVYEAR           object\n",
      "                   ...   \n",
      "SY_STATUS_TEXT     object\n",
      "SCHOOL_LEVEL       object\n",
      "AS                  int64\n",
      "CHARTER_TEXT       object\n",
      "MAGNET_TEXT        object\n",
      "Length: 77, dtype: object\n",
      "First 3 rows:\n",
      "OBJECTID\n",
      "0    1\n",
      "1    2\n",
      "2    3\n",
      "Name: OBJECTID, dtype: int64\n",
      "\n",
      "X\n",
      "0   -86.2062\n",
      "1   -86.2049\n",
      "2   -86.2201\n",
      "Name: X, dtype: float64\n",
      "\n",
      "Y\n",
      "0    34.2602\n",
      "1    34.2622\n",
      "2    34.2733\n",
      "Name: Y, dtype: float64\n",
      "\n",
      "NCESSCH\n",
      "0    1.000050e+10\n",
      "1    1.000050e+10\n",
      "2    1.000050e+10\n",
      "Name: NCESSCH, dtype: float64\n",
      "\n",
      "SURVYEAR\n",
      "0    2020-2021\n",
      "1    2020-2021\n",
      "2    2020-2021\n",
      "Name: SURVYEAR, dtype: object\n",
      "\n",
      "STABR\n",
      "0    AL\n",
      "1    AL\n",
      "2    AL\n",
      "Name: STABR, dtype: object\n",
      "\n",
      "LEAID\n",
      "0    100005\n",
      "1    100005\n",
      "2    100005\n",
      "Name: LEAID, dtype: int64\n",
      "\n",
      "ST_LEAID\n",
      "0    AL-101\n",
      "1    AL-101\n",
      "2    AL-101\n",
      "Name: ST_LEAID, dtype: object\n",
      "\n",
      "LEA_NAME\n",
      "0    Albertville City\n",
      "1    Albertville City\n",
      "2    Albertville City\n",
      "Name: LEA_NAME, dtype: object\n",
      "\n",
      "SCH_NAME\n",
      "0          Albertville Middle School\n",
      "1            Albertville High School\n",
      "2    Albertville Intermediate School\n",
      "Name: SCH_NAME, dtype: object\n",
      "\n",
      "LSTREET1\n",
      "0     600 E Alabama Ave\n",
      "1      402 E McCord Ave\n",
      "2    901 W McKinney Ave\n",
      "Name: LSTREET1, dtype: object\n",
      "\n",
      "LCITY\n",
      "0    Albertville\n",
      "1    Albertville\n",
      "2    Albertville\n",
      "Name: LCITY, dtype: object\n",
      "\n",
      "LSTATE\n",
      "0    AL\n",
      "1    AL\n",
      "2    AL\n",
      "Name: LSTATE, dtype: object\n",
      "\n",
      "LZIP\n",
      "0    35950\n",
      "1    35950\n",
      "2    35950\n",
      "Name: LZIP, dtype: int64\n",
      "\n",
      "PHONE\n",
      "0    (256)878-2341\n",
      "1    (256)894-5000\n",
      "2    (256)878-7698\n",
      "Name: PHONE, dtype: object\n",
      "\n",
      "GSLO\n",
      "0    7\n",
      "1    9\n",
      "2    5\n",
      "Name: GSLO, dtype: object\n",
      "\n",
      "GSHI\n",
      "0     8\n",
      "1    12\n",
      "2     6\n",
      "Name: GSHI, dtype: object\n",
      "\n",
      "VIRTUAL\n",
      "0    Not Virtual\n",
      "1    Not Virtual\n",
      "2    Not Virtual\n",
      "Name: VIRTUAL, dtype: object\n",
      "\n",
      "TOTFRL\n",
      "0    332\n",
      "1    456\n",
      "2    330\n",
      "Name: TOTFRL, dtype: int64\n",
      "\n",
      "FRELCH\n",
      "0    332\n",
      "1    456\n",
      "2    330\n",
      "Name: FRELCH, dtype: int64\n",
      "\n",
      "REDLCH\n",
      "0    0\n",
      "1    0\n",
      "2    0\n",
      "Name: REDLCH, dtype: int64\n",
      "\n",
      "PK\n",
      "0    0\n",
      "1    0\n",
      "2    0\n",
      "Name: PK, dtype: int64\n",
      "\n",
      "KG\n",
      "0    0\n",
      "1    0\n",
      "2    0\n",
      "Name: KG, dtype: int64\n",
      "\n",
      "G01\n",
      "0    0\n",
      "1    0\n",
      "2    0\n",
      "Name: G01, dtype: int64\n",
      "\n",
      "G02\n",
      "0    0\n",
      "1    0\n",
      "2    0\n",
      "Name: G02, dtype: int64\n",
      "\n",
      "G03\n",
      "0    0\n",
      "1    0\n",
      "2    0\n",
      "Name: G03, dtype: int64\n",
      "\n",
      "G04\n",
      "0    0\n",
      "1    0\n",
      "2    0\n",
      "Name: G04, dtype: int64\n",
      "\n",
      "G05\n",
      "0      0\n",
      "1      0\n",
      "2    439\n",
      "Name: G05, dtype: int64\n",
      "\n",
      "G06\n",
      "0      0\n",
      "1      0\n",
      "2    452\n",
      "Name: G06, dtype: int64\n",
      "\n",
      "G07\n",
      "0    469\n",
      "1      0\n",
      "2      0\n",
      "Name: G07, dtype: int64\n",
      "\n",
      "G08\n",
      "0    439\n",
      "1      0\n",
      "2      0\n",
      "Name: G08, dtype: int64\n",
      "\n",
      "G09\n",
      "0      0\n",
      "1    421\n",
      "2      0\n",
      "Name: G09, dtype: int64\n",
      "\n",
      "G10\n",
      "0      0\n",
      "1    427\n",
      "2      0\n",
      "Name: G10, dtype: int64\n",
      "\n",
      "G11\n",
      "0      0\n",
      "1    384\n",
      "2      0\n",
      "Name: G11, dtype: int64\n",
      "\n",
      "G12\n",
      "0      0\n",
      "1    374\n",
      "2      0\n",
      "Name: G12, dtype: int64\n",
      "\n",
      "G13\n",
      "0    0\n",
      "1    0\n",
      "2    0\n",
      "Name: G13, dtype: int64\n",
      "\n",
      "TOTAL\n",
      "0     908\n",
      "1    1606\n",
      "2     891\n",
      "Name: TOTAL, dtype: int64\n",
      "\n",
      "MEMBER\n",
      "0     908\n",
      "1    1606\n",
      "2     891\n",
      "Name: MEMBER, dtype: int64\n",
      "\n",
      "AM\n",
      "0    2\n",
      "1    1\n",
      "2    4\n",
      "Name: AM, dtype: int64\n",
      "\n",
      "HI\n",
      "0    469\n",
      "1    785\n",
      "2    481\n",
      "Name: HI, dtype: int64\n",
      "\n",
      "BL\n",
      "0    33\n",
      "1    70\n",
      "2    24\n",
      "Name: BL, dtype: int64\n",
      "\n",
      "WH\n",
      "0    371\n",
      "1    706\n",
      "2    345\n",
      "Name: WH, dtype: int64\n",
      "\n",
      "HP\n",
      "0    0\n",
      "1    0\n",
      "2    1\n",
      "Name: HP, dtype: int64\n",
      "\n",
      "TR\n",
      "0    29\n",
      "1    38\n",
      "2    29\n",
      "Name: TR, dtype: int64\n",
      "\n",
      "FTE\n",
      "0    42.0\n",
      "1    82.0\n",
      "2    41.0\n",
      "Name: FTE, dtype: float64\n",
      "\n",
      "LATCOD\n",
      "0    34.2602\n",
      "1    34.2622\n",
      "2    34.2733\n",
      "Name: LATCOD, dtype: float64\n",
      "\n",
      "LONCOD\n",
      "0   -86.2062\n",
      "1   -86.2049\n",
      "2   -86.2201\n",
      "Name: LONCOD, dtype: float64\n",
      "\n",
      "ULOCALE\n",
      "0    32-Town: Distant\n",
      "1    32-Town: Distant\n",
      "2    32-Town: Distant\n",
      "Name: ULOCALE, dtype: object\n",
      "\n",
      "NMCNTY\n",
      "0    Marshall County\n",
      "1    Marshall County\n",
      "2    Marshall County\n",
      "Name: NMCNTY, dtype: object\n",
      "\n",
      "STUTERATIO\n",
      "0    21.62\n",
      "1    19.59\n",
      "2    21.73\n",
      "Name: STUTERATIO, dtype: float64\n",
      "\n",
      "TITLEI\n",
      "0    1-Yes\n",
      "1    1-Yes\n",
      "2    1-Yes\n",
      "Name: TITLEI, dtype: object\n",
      "\n",
      "STITLEI\n",
      "0    1-Yes\n",
      "1    1-Yes\n",
      "2    1-Yes\n",
      "Name: STITLEI, dtype: object\n",
      "\n",
      "AMALM\n",
      "0    1\n",
      "1    1\n",
      "2    3\n",
      "Name: AMALM, dtype: int64\n",
      "\n",
      "AMALF\n",
      "0    1\n",
      "1    0\n",
      "2    1\n",
      "Name: AMALF, dtype: int64\n",
      "\n",
      "ASALM\n",
      "0    0\n",
      "1    4\n",
      "2    4\n",
      "Name: ASALM, dtype: int64\n",
      "\n",
      "ASALF\n",
      "0    4\n",
      "1    2\n",
      "2    3\n",
      "Name: ASALF, dtype: int64\n",
      "\n",
      "HIALM\n",
      "0    239\n",
      "1    414\n",
      "2    228\n",
      "Name: HIALM, dtype: int64\n",
      "\n",
      "HIALF\n",
      "0    230\n",
      "1    371\n",
      "2    253\n",
      "Name: HIALF, dtype: int64\n",
      "\n",
      "BLALM\n",
      "0    18\n",
      "1    33\n",
      "2    12\n",
      "Name: BLALM, dtype: int64\n",
      "\n",
      "BLALF\n",
      "0    15\n",
      "1    37\n",
      "2    12\n",
      "Name: BLALF, dtype: int64\n",
      "\n",
      "WHALM\n",
      "0    187\n",
      "1    368\n",
      "2    177\n",
      "Name: WHALM, dtype: int64\n",
      "\n",
      "WHALF\n",
      "0    184\n",
      "1    338\n",
      "2    168\n",
      "Name: WHALF, dtype: int64\n",
      "\n",
      "HPALM\n",
      "0    0\n",
      "1    0\n",
      "2    0\n",
      "Name: HPALM, dtype: int64\n",
      "\n",
      "HPALF\n",
      "0    0\n",
      "1    0\n",
      "2    1\n",
      "Name: HPALF, dtype: int64\n",
      "\n",
      "TRALM\n",
      "0    19\n",
      "1    17\n",
      "2    17\n",
      "Name: TRALM, dtype: int64\n",
      "\n",
      "TRALF\n",
      "0    10\n",
      "1    21\n",
      "2    12\n",
      "Name: TRALF, dtype: int64\n",
      "\n",
      "TOTMENROL\n",
      "0    0\n",
      "1    0\n",
      "2    0\n",
      "Name: TOTMENROL, dtype: int64\n",
      "\n",
      "TOTFENROL\n",
      "0    0\n",
      "1    0\n",
      "2    0\n",
      "Name: TOTFENROL, dtype: int64\n",
      "\n",
      "STATUS\n",
      "0    1\n",
      "1    1\n",
      "2    1\n",
      "Name: STATUS, dtype: int64\n",
      "\n",
      "UG\n",
      "0    0\n",
      "1    0\n",
      "2    0\n",
      "Name: UG, dtype: int64\n",
      "\n",
      "AE\n",
      "0    0\n",
      "1    0\n",
      "2    0\n",
      "Name: AE, dtype: int64\n",
      "\n",
      "SCHOOL_TYPE_TEXT\n",
      "0    Regular school\n",
      "1    Regular school\n",
      "2    Regular school\n",
      "Name: SCHOOL_TYPE_TEXT, dtype: object\n",
      "\n",
      "SY_STATUS_TEXT\n",
      "0    Currently operational \n",
      "1    Currently operational \n",
      "2    Currently operational \n",
      "Name: SY_STATUS_TEXT, dtype: object\n",
      "\n",
      "SCHOOL_LEVEL\n",
      "0    Middle\n",
      "1      High\n",
      "2    Middle\n",
      "Name: SCHOOL_LEVEL, dtype: object\n",
      "\n",
      "AS\n",
      "0    4\n",
      "1    6\n",
      "2    7\n",
      "Name: AS, dtype: int64\n",
      "\n",
      "CHARTER_TEXT\n",
      "0    No\n",
      "1    No\n",
      "2    No\n",
      "Name: CHARTER_TEXT, dtype: object\n",
      "\n",
      "MAGNET_TEXT\n",
      "0    No\n",
      "1    No\n",
      "2    No\n",
      "Name: MAGNET_TEXT, dtype: object\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get data type of each column\n",
    "print(\"Data types:\")\n",
    "print(df.dtypes)\n",
    "\n",
    "# Print the first 3 rows of each column\n",
    "print(\"First 3 rows:\")\n",
    "for col in df.columns:\n",
    "    print(col)\n",
    "    print(df[col].head(3))\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14b5f71e",
   "metadata": {},
   "source": [
    "At this point, I did some looking around after making a table in excel because I wanted to see some of the columns for myself. For simplicity, I did most of the next few steps directly in excel, but the code to complete the same steps using pandas is included below.\n",
    "\n",
    "I used excel to quickly check what entries were in each column, and started considering what would or would not be useful given my final objective of making a story in Tableau. Overall, I found there were quite a few columns that I would have liked to use, but they didn't fit in nicely with what I was trying to accomplish, or the data was too imcomplete to use - such as male and female numbers of the included demographics.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e0323526",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of columns to remove - these are all unnecessary or incomplete\n",
    "cols_to_remove = ['X', 'Y', 'STABR', 'LEAID', 'ST_LEAID', 'LEA_NAME', 'LZIP', 'G13', 'PHONE', 'AMALM', 'AMALF', 'ASALM', 'ASALF', 'HIALM', 'HIALF', 'BLALM', 'BLALF', 'WHALM', 'WHALF', 'HPALM', 'HPALF', 'TRALM', 'TRALF', 'TOTMENROL', 'TOTFENROL', 'UG', 'AE']\n",
    "\n",
    "# Drop the columns\n",
    "df.drop(cols_to_remove, axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "785f9f2c",
   "metadata": {},
   "source": [
    "After checking in excel again, I realized that the G13 column didn't have any necessary information, and the schools that ended up dropped in the end did not have any students in G13, so I also dropped that column as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d021475e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking summary and table info again after removing the columns to check if there's anything I missed\n",
    "print(\"Column names:\")\n",
    "print(list(df.columns))\n",
    "\n",
    "print(\"Number of columns:\", len(df.columns))\n",
    "print(\"Number of rows:\", len(df))\n",
    "\n",
    "# Print the first 3 rows of each column\n",
    "print(\"First 3 rows:\")\n",
    "for col in df.columns:\n",
    "    print(col)\n",
    "    print(df[col].head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76cbeb8c",
   "metadata": {},
   "source": [
    "After removing some unnecessary columns, I wanted to start removing unnecessary records. The first column I looked at was \"SY_STATUS_TEXT\" where I wanted to keep schools that were currently open or newly opened, but did not want to keep any of the closed schools due to low numbers and low impact on the data set. Further, I did not anticipate needing to look at the results or impact of school closures for this project - although that would be worth investigating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5a1f7fcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of removed records: 2003\n",
      "Number of removed records by state:\n",
      " TX    613\n",
      "AZ    172\n",
      "FL    110\n",
      "NC     79\n",
      "MN     59\n",
      "WA     56\n",
      "IL     55\n",
      "ND     50\n",
      "OH     48\n",
      "NY     47\n",
      "MI     44\n",
      "UT     44\n",
      "ID     41\n",
      "NV     39\n",
      "AR     37\n",
      "WI     33\n",
      "TN     29\n",
      "SC     27\n",
      "AL     26\n",
      "SD     25\n",
      "CO     24\n",
      "NJ     24\n",
      "NE     22\n",
      "LA     22\n",
      "OR     20\n",
      "PA     19\n",
      "MO     18\n",
      "GA     18\n",
      "KY     18\n",
      "ME     17\n",
      "OK     15\n",
      "IN     14\n",
      "CA     13\n",
      "MS     13\n",
      "IA     13\n",
      "VA     12\n",
      "AK     10\n",
      "DC     10\n",
      "MA      9\n",
      "VT      8\n",
      "MT      7\n",
      "DE      7\n",
      "WY      7\n",
      "NM      6\n",
      "KS      5\n",
      "MD      4\n",
      "WV      4\n",
      "NH      4\n",
      "HI      2\n",
      "CT      2\n",
      "RI      2\n",
      "Name: LSTATE, dtype: int64\n",
      "Operational data:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Filter the data based on SY_STATUS_TEXT column\n",
    "operational_data = df[df['SY_STATUS_TEXT'].str.strip().isin(['Currently operational', 'Newly opened'])]\n",
    "\n",
    "# Count the number of removed records\n",
    "removed_records = len(df) - len(operational_data)\n",
    "\n",
    "# Count the number of removed records by LSTATE\n",
    "removed_by_state = df[~df['SY_STATUS_TEXT'].str.strip().isin(['Currently operational', 'Newly opened'])]['LSTATE'].value_counts()\n",
    "\n",
    "# Display the data without truncation\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "# Display the filtered data and the counts\n",
    "print('Number of removed records:', removed_records)\n",
    "print('Number of removed records by state:\\n', removed_by_state)\n",
    "print('Operational data:')\n",
    "print(operational_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2b18356f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      LSTATE  counts\n",
      "Total          11533\n",
      "12        IL    4384\n",
      "42        UT    1113\n",
      "3         AZ    1054\n",
      "41        TX     790\n",
      "7         FL     548\n",
      "21        MN     392\n",
      "4         CA     389\n",
      "45        WA     299\n",
      "43        VA     268\n",
      "1         AL     228\n",
      "20        MI     182\n",
      "22        MO     176\n",
      "23        MS     161\n",
      "15        KY     155\n",
      "32        NY     133\n",
      "33        OH     132\n",
      "29        NJ     101\n",
      "27        NE      92\n",
      "31        NV      83\n",
      "40        TN      70\n",
      "25        NC      69\n",
      "38        SC      67\n",
      "46        WI      66\n",
      "47        WV      65\n",
      "13        IN      57\n",
      "26        ND      46\n",
      "18        MD      44\n",
      "11        ID      39\n",
      "16        LA      38\n",
      "19        ME      34\n",
      "2         AR      30\n",
      "39        SD      28\n",
      "8         GA      26\n",
      "36        PA      23\n",
      "5         CO      20\n",
      "30        NM      17\n",
      "44        VT      16\n",
      "34        OK      12\n",
      "6         DE      12\n",
      "0         AK      12\n",
      "35        OR      11\n",
      "37        RI       8\n",
      "14        KS       8\n",
      "17        MA       8\n",
      "24        MT       8\n",
      "48        WY       8\n",
      "28        NH       6\n",
      "10        IA       4\n",
      "9         HI       1\n"
     ]
    }
   ],
   "source": [
    "# Count the number of incomplete schools by state\n",
    "incomplete_data = df[(df[\"FTE\"] == 0) | (df[\"FTE\"] == 1) \n",
    "                     & (df[\"STUTERATIO\"] == -2) \n",
    "                     | (df[\"STUTERATIO\"] == -1) \n",
    "                     | (df[\"STUTERATIO\"] == 0) \n",
    "                     | (df[\"STUTERATIO\"] == 1) \n",
    "                     & (df[\"MEMBER\"] == 0) \n",
    "                     | (df[\"MEMBER\"] == 1) \n",
    "                     & (df[\"SCHOOL_TYPE_TEXT\"] == \"Regular school\") \n",
    "                     & (df[\"SY_STATUS_TEXT\"].str.strip() == \"Currently operational\")].groupby(\"LSTATE\").size().reset_index(name='counts')\n",
    "\n",
    "# Add a total row\n",
    "total = incomplete_data[\"counts\"].sum()\n",
    "incomplete_data.loc[\"Total\"] = [\"\", total]\n",
    "\n",
    "# Sort the output by counts, from largest to smallest\n",
    "incomplete_data = incomplete_data.sort_values(\"counts\", ascending=False)\n",
    "\n",
    "# Print the output\n",
    "print(incomplete_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d41e1c2",
   "metadata": {},
   "source": [
    "At this point, I did a bit more digging into each column and checked some variations of schools with unexpected totals for Students, Teachers (FTE), and S:T Ratio.\n",
    "\n",
    "For the first test, I looked at schools that were listed as \"Currently Operational\" and had Total_Teachers_Rounded to either 1 or 0. To narrow things down more, I included schools that had S:T Ratio of 0, and at least 1 Student.\n",
    "\n",
    "To address the states I adjusted heavily - Utah, Arizona, and Illinois - that were otherwise blank or largely incomplete, to the extent that they were either wholly or almost entirely excluded from the analysis. Likely worth explaining that in a different setting, I would probably approach this issue differently, but my goal here was a complete dataset, rather than moving forward without the full set of states - especially when a simple alternative was readily available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62e9b71f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the DataFrame to only include records where \"FTE\" is 0 and \"SY_STATUS_TEXT\" is \"Currently operational\"\n",
    "incomplete_data = df[(df[\"FTE\"] == 0) & (df[\"SY_STATUS_TEXT\"] == \"Currently operational\")]\n",
    "\n",
    "# Count the number of records per state in the filtered DataFrame\n",
    "state_count = incomplete_data[\"LSTATE\"].value_counts()\n",
    "\n",
    "# Sort the counts by state abbreviation\n",
    "state_counts = state_counts.sort_index()\n",
    "\n",
    "# Print the state counts\n",
    "print(state_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc235aa7",
   "metadata": {},
   "source": [
    "Below, I'm going to check unique values in the 'LSTATE' column. I'll end up removing this, but interesting detail I noticed (after ages working with this data), the State Abbr column includes a unique abbr for schools on Indian Reservations. So even though the schools are in different states, there was a way to group by reservations as a whole. This could've been an avenue toward looking at the relatively grim outlook facing Am. Indian/Native American students. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb59ff3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of distinct values in the \"LSTATE\" column\n",
    "state_counts = df[\"LSTATE\"].value_counts()\n",
    "\n",
    "# Print the state counts\n",
    "print(state_counts)\n",
    "\n",
    "df.to_csv(\"/Users/camerongomez/Desktop/Python Cleaning/School_Test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f14c6787",
   "metadata": {},
   "source": [
    "After removing columns and incomplete records, I decided to join my two main csv files, Public School Characteristics and IPR/Poverty Statistics. I realized that I didn't actually need to do a join with Teacher Salary, so I left that for Tableau.\n",
    "\n",
    "In the end, I used merge rather than join because it ended up being a little easier to match the columns on school name, rather than index number, due to the different order. However, this did take some massaging. To make sure that the join was giving me the desired results, I used two separate columns and checked the results against each other (the columns used were \"SCH_NAME\" and \"NCESSCH\" - the school name column seemed to give the desired results, but NCESSCH is a unique school ID number which removed any possible issues due to white space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69709d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the IPR_Current.csv file\n",
    "ipr_df = pd.read_csv(\"/Users/camerongomez/Desktop/Python Cleaning/IPR_Current.csv\")\n",
    "\n",
    "# Inner join the two DataFrames on the SCH_NAME column\n",
    "df = pd.merge(df, ipr_df, on=\"SCH_NAME\", how=\"inner\")\n",
    "\n",
    "# Print the number of rows in the merged DataFrame\n",
    "print(\"Number of rows after merge:\", len(df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f779a159",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the merged DataFrame to a CSV file\n",
    "df.to_csv(\"/Users/camerongomez/Desktop/Python Cleaning/School_Join_Final.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88470e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove duplicates based on the \"SCH_NAME\" column\n",
    "df.drop_duplicates(subset=\"SCH_NAME\", keep=\"first\", inplace=True)\n",
    "# Save the merged DataFrame to a CSV file\n",
    "df.to_csv(\"/Users/camerongomez/Desktop/Python Cleaning/School_Join_Final.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "638f4532",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "At this point, I brought both of my csv files into Tableau to start making plots and investigating using charts, which ended up bringing me to making some additional tables and calculations for percentages and averages related to Demographics, Locales, and IPR. As mentioned at the beginning of this notebook, I did not include those steps here, however, you can see them as part of the finished Tableau workbook found here: https://public.tableau.com/views/Capstone2_Public_Schools_US_Draft/Story-PublicSchoolCharacteristics?:language=en-US&publish=yes&:display_count=n&:origin=viz_share_link"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
